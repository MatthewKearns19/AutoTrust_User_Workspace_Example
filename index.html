<!DOCTYPE html>
<html>
<title>Auto-Trust-Framework-Description</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://www.w3schools.com/lib/w3-colors-2021.css">
<style>
html,body,h1,h2,h3,h4 {font-family:"Lato", sans-serif}
.mySlides {display:none}
.w3-tag, .fa {cursor:pointer}
.w3-tag {height:15px;width:15px;padding:0;margin-top:6px}

</style>
<body>

<!-- Content -->
<div class="w3-content" style="max-width:1050px;margin-top:20px;margin-bottom:20">

  <div class="w3-panel">
    <div class="w3-row-3">
      <h1 class="w3-margin-bottom"><b>Welcome to Auto-Trust, an automated visual testing framework.</b></h1>
    </div>
  </div>
  <div class="w3-panel w3-margin-bottom">
    <p>As final year college software project, Auto-Trust was undertaken to explore and emphasize the importance
    of automated visual testing during the Software Development Lifecycle. Auto-Trust is a collection technologies organized into a
    specific system architechture to facilitate visual test automation of a web application’s User Interface. Auto-Trust aims to guide
    your own project development as it can be used as a base framework for your own automation needs, offering automated visual assessment tests that can be
    executed on your development, staging, or production environments. The automated tests can also be encapsulated within a continuous integration/continuous
     delivery architecture, as was demonstrated in this project development. Testing is done in a Behaviour-Driven Development approach, where tests are created
     to compare expected outcomes of existing developments.</p>
    <p>These visual comparisons are achieved with various tools and technologies used to capture site element differences, via screenshotted pixel
      comparison, and also the quality of any instances of site images can be assessed via a custom-built machine learning model -
       a Convolutional Neural Network Image Classifier (CNN) that achieves 96.9% accuracy in assessing image quality under six
       categories: high resolution, blur, colour distortion, JPEG compression, noise, and spatial distortion. Assessing these
       qualities are essential in terms of customer usability and general development lifecycle endeavors, such as speeding up
       developments to exceed deadlines, or avoiding painful deployment rollbacks.</p>
  </div>

  <!-- Slideshow -->
  <div class="w3-container w3-margin-bottom">
    <div class="w3-display-container mySlides">
      <img src="/images/Auto-trust.png" style="width:100%">
      <div class="w3-display-topleft w3-container w3-padding-32">
      </div>
    </div>
    <div class="w3-display-container mySlides">
      <img src="/images/Autotest.PNG" style="width:100%">
      <div class="w3-display-middle w3-container w3-padding-32">
      </div>
    </div>
    <div class="w3-display-container mySlides">
      <img src="/images/ML.PNG" style="width:100%">
      <div class="w3-display-topright w3-container w3-padding-32">
      </div>
    </div>

    <!-- Slideshow next/previous buttons -->
    <div class="w3-container w3-dark-grey w3-padding w3-xlarge">
      <div class="w3-left" onclick="plusDivs(-1)"><i class="fa fa-arrow-circle-left w3-hover-text-teal"></i></div>
      <div class="w3-right" onclick="plusDivs(1)"><i class="fa fa-arrow-circle-right w3-hover-text-teal"></i></div>

      <div class="w3-center">
        <span class="w3-tag demodots w3-border w3-transparent w3-hover-white" onclick="currentDiv(1)"></span>
        <span class="w3-tag demodots w3-border w3-transparent w3-hover-white" onclick="currentDiv(2)"></span>
        <span class="w3-tag demodots w3-border w3-transparent w3-hover-white" onclick="currentDiv(3)"></span>
      </div>
    </div>
  </div>




  <!-- Grid -->
  <div class="w3-row w3-container">
    <div class="w3-center w3-padding-64">
      <span class="w3-xlarge w3-bottombar w3-border-dark-grey w3-padding-16">The nuts and bolts behind Auto-Trust</span>
    </div>

    <div class="w3-panel w3-padding-32 w3-light-grey w3-container w3-padding-16 w3-margin-bottom">
      <div class="w3-container">
        <h3>Testing Framework Integrations</h3>
        <p>The framework provides a base setup for automation test scripts, written in Python Behave to execute test cases in the structured,
          natural language, behavioural-scenario format of the 'Gherkin language'. By utilizing Python Behave, this follows a Behaviour-Driven Development testing approach
          within your development lifecycle, promoting a testing workflow of balanced communication between test engineers, developers, and business. The test scripts execute
          in the browser with Selenium, capturing site elements and comparing them to expected values. This automated testing framework can be
          connected to your CI/CD pipelines to achieve a fully automated integration.</p>
      </div>
    </div>

    <div class="w3-panel m6 w3-light-grey w3-container w3-padding-16 w3-margin-bottom">
      <div class="w3-container">
        <h3>Site Classification</h3>
        <p>Sitting behind your normal test cases is the option to utilize image comparison under two metrics: <br> 1. Identical User Interface
          comparison - to highlight any areas of your site that have changed during development. These changes may cause errors that could potentially be missed
          by manual testing or other system tests. Errors such as html tags that have not been closed or perhaps unexpected text formatting due to unhandled
          encoding/decoding. This comparison is achieved by capturing a screenshot of a site location specified in the test, and comparing its 'exact pixel values' vs. a pre-defined screenshot,
          seeking out any pixel contours if the images do not match and highlighting these areas of difference with a red bounding box. <br> 2. Image quality classification - to highlight
          the quality of an image within your site as it may have lost quality through your deployment pipeline, such as JPEG compression. It is difficult to locate what
          is causing occurrences of image distortion, and having a second pair of eyes on your site with trained logic behind image quality assessment can point you in the right
          direction to a solution. If the User Interface contains an image that they want to assess, this second comparison metric can be invoked within a test and the image quality
          assessment is achieved by assessing the 'pixel features' of this image, predicting/returning the image quality after being passes through the Convolutional Neural Network.</p>
      </div>
    </div>

    <div class="w3-panel m6 w3-light-grey w3-container w3-padding-16 w3-margin-bottom">
      <div class="w3-container">
        <h3>Model Training</h3>
        <p>In the 'models' folder you can find a Convolutional Neural Network. This Machine learning Model is a custom-built model trained to
          classify the pixel features of given image, trained on the KADID-10k Image Database (can be found at
          http://database.mmsp-kn.de/kadid-10k-database.html). The dataset is composed of the same images with various levels
          of distortions applied, providing the CNN with image features to incrementally learn upon. Other Models were experimented,
          such as applying transfer learning to a MobileNet model by fine-tuning the layers of the model to adjust its knowledge and
          decipher new features bases on our own task at hand. The custom built model yielded better results and was chosen instead.</p>
      </div>
    </div>

    <div class="w3-panel m6 center w3-light-grey w3-container w3-padding-16 w3-margin-bottom">
      <div class="w3-container ">
      <h3>Combining it all together</h3>
        <p> The behavioural test ‘Scenario’ is defined in the 'Python Behave Feature' file ('.feature' file extension). The Scenario outlines the test steps that a user is to take and the expected result
          of these steps, written in the natural 'Gherkin' language syntax - 'Given', 'When', 'Then', 'And'. Each step in the Scenario outlined has a corresponding
          function in the steps file ('.step' file extension), and any parameters defined in the Scenario's steps will be passed to the corresponding function to be used.
          The steps execute the desired test in a browser via 'Selenium webdriver'. To adjust the tests to your own workflow, use Selenium to take a screenshot of the browser at a
          desired location, as demonstrated and described in the supplied codebase. Selenium can mock a real user by using 'ActionChains', moving the browsers cursor
          to a specified site location by locating a browser element, which in turn allows you to instruct the test to capture a screenshot at your desired site location.
          Move the screenshots from the 'browser_screenshot_outputs' directory and store them the 'pre_defined_screenshots' directory with an associated image name (to be used by the tests as a label).
          This image name/label can then be defined in your scenarios as a parameter of a test step, and the functions for this step will trigger image
          comparison on the browser's captured screenshot that has just been labeled vs. the pre-defined labeled screenshot. In this sense, using the name/label as a means of locating the two screenshots to compare. Any pixel
          differences (errors) will be highlighted within an red bounding box, triggering a failed test results and stored in the 'failed_comparisons' directory. If image distortion classification is invoked,
          the image quality will be classified and will also be returned as a test result.</p>
      </div>
    </div>

    <div class="w3-panel m6 center w3-light-grey w3-container w3-padding-16 w3-margin-bottom">
      <div class="w3-container ">
      <h3>Results</h3>
        <p> Normal test assertions of the browser elements fail when the asserted values to not match. Here is an example of the heading text of this site failing assertion when the 'Framework' text is missing: </p>
        <img src="/images2/Assertion.PNG" style="width:30%">

        <p> But what if there is an area that is not accounted for in these test assertions? They will not be captured and the tets will pass. However, if visual comparison is invoked in the tests on a new screenshot vs. a predefined screenshot,
          the test will fail if the similarity score is less that 100%. We can see the result of an unclosed HTML paragraph tag being captured along with the failed heading text from the above assertion: </p>
        <img src="/images2/bounding_box.PNG" style="width:80%">

        <p> But then, what if an image within the site fails the above exact pixel value comparison and we do not know why? If image quality assessment is invoked in the tests, we can see that not only does
          it output a failed result, but it has also classified the image quality as noise distortion. The same is true for the other categories of image quality that the CNN is trained upon, and the test
          would only pass if high resolution was classified: </p>
        <img src="/images2/noise_classified.PNG" style="width:80%">

      </div>
    </div>

    <div class="w3-panel m6 w3-light-grey w3-container w3-padding-16 w3-margin-bottom">
      <div class="w3-container">
        <h3>Issues to be future developed</h3>
        <p>Currently, the exact pixel comparison of a browser captured screenshot vs. a predefined screenshot is susceptible to unreadable failed
          results when a large element is removed, in turn causing a large page shift. In this case of a large page shift, many areas of the page are effected and also get flagged as an error.
          The failed comparison result is unreadable in terms of pinpointing the root cause within many highlighted failed areas. Future development of
          differentiating when to highlight errors needs to be tackled, with more intelligent methods of comparison.</p>
      </div>
    </div>

  </div>



  <!-- Grid -->
  <div class="w3-row-padding">
    <div class="w3-center w3-padding-64">
      <span class="w3-xlarge w3-bottombar w3-border-dark-grey w3-padding-16">Image Quality Distortion Assessment</span>
    </div>

    <div class="w3-third w3-margin-bottom">
      <div class="w3-card-4 w3-light-grey">
        <img src="/images/origional.png" style="width:100%">
        <div class="w3-container">
          <p>Origional Image</p>
          <p class="w3-opacity">An example of an origional image from the dataset.</p>
        </div>
      </div>
    </div>

    <div class="w3-third w3-margin-bottom">
      <div class="w3-card-4 w3-light-grey">
        <img src="/images/blur.png" style="width:100%">
        <div class="w3-container">
          <p>Blur Distortion</p>
          <p class="w3-opacity">The origional image with blurred distortion applied.<br></p>
        </div>
      </div>
    </div>

    <div class="w3-third w3-margin-bottom">
      <div class="w3-card-4 w3-light-grey">
        <img src="/images/color_distortion.png" style="width:100%">
        <div class="w3-container">
          <p>Colour Distortion</p>
          <p class="w3-opacity">The origional image with colour distortion applied.</p>
        </div>
      </div>
    </div>

    <div class="w3-third w3-margin-bottom">
      <div class="w3-card-4 w3-light-grey">
        <img src="/images/compression.png" style="width:100%">
        <div class="w3-container">
          <p>Compression Distortion</p>
          <p class="w3-opacity">The origional image with JPEG compression distortion applied.</p>
        </div>
      </div>
    </div>

    <div class="w3-third w3-margin-bottom">
      <div class="w3-card-4 w3-light-grey">
        <img src="/images/noise.png" style="width:100%">
        <div class="w3-container">
          <p>Noise Distortion</p>
          <p class="w3-opacity">The origional image with noise distortion applied.</p>
        </div>
      </div>
    </div>

    <div class="w3-third w3-margin-bottom">
      <div class="w3-card-4 w3-light-grey">
        <img src="/images/spatial_distortion.png" style="width:100%">
        <div class="w3-container">
          <p>Spatial Distortion</p>
          <p class="w3-opacity">The origional image with spatial distortion applied.</p>
        </div>
      </div>
    </div>

    <div class="w3-row-padding w3-center">
      <div class="w6-col m6 w3-container w3-padding-32 w3-margin-bottom">
        <p class="float-left">The 10,000 origional images from a the Kadid10k dataset had various types of distortions applied for each distortion category mentioned above.
           Each type of distortion also had three levels of distortion applied, low distortion, medium distortion, and high distortion. We can see
           with JPEG compression, noise and spatial distortion that it may be easy to miss these manually, and if it was noticed, how are we supposed
            to know what type of distortion is occuring to resolve the issue.</p>
           <p>Blurs: <br><p class="w3-opacity">
                   - Gaussian blur<br>
                   - Lens blur<br>
                   - Motion blur<br></p><p>
              Color distortions<br><p class="w3-opacity">
                   - Color diffusion<br>
                   - Color shift<br>
                   - Color quantization<br>
                   - Color saturation 1<br>
                   - Color saturation 2<br></p><p>
              Compression<br><p class="w3-opacity">
                   - JPEG2000 standard compression<br>
                   - JPEG standard compression<br></p><p>
              Noise<br><p class="w3-opacity">
                   - Gaussian white noise<br>
                   - Gaussian white noise in color component)<br>
                   - Impulse noise<br>
                   - Multiplicative noise<br>
                   - Denoise<br></p><p>
              Spatial distortions:<br><p class="w3-opacity">
                   - Jitter<br>
                   - Non-eccentricity patch<br>
                   - Pixelate<br>
                   - Quantization</p>

      </div>
    </div>

  </div>



</div>


<footer class="w3-container w3-light-grey w3-center">
  <div class="w3-content" style="max-width:1050px;">
    <a href="#" class="w3-button w3-dark-grey w3-margin"><i class="fa fa-arrow-up w3-margin-right"></i>Back To The Top</a>
    <h5>Citation of the Dataset used in training the Convolutional Neural Network:</h5>
    <p class="w3-center">Lin, H., Hosu V., Saupe D., 2008. KADID-10k: A Large-scale Artificially <br>
                        Distorted IQA Database. [online] Visual Quality Assessment (VQA). <br>
                        Available at: "http://database.mmsp-kn.de/kadid-10k-database.html <br>
                        [Accessed 01 May 2021], pp. 1-3.
    </p>
  </div>
</footer>


<script>
// Slideshow
var slideIndex = 1;
showDivs(slideIndex);

function plusDivs(n) {
  showDivs(slideIndex += n);
}

function currentDiv(n) {
  showDivs(slideIndex = n);
}

function showDivs(n) {
  var i;
  var x = document.getElementsByClassName("mySlides");
  var dots = document.getElementsByClassName("demodots");
  if (n > x.length) {slideIndex = 1}
  if (n < 1) {slideIndex = x.length} ;
  for (i = 0; i < x.length; i++) {
    x[i].style.display = "none";
  }
  for (i = 0; i < dots.length; i++) {
    dots[i].className = dots[i].className.replace(" w3-white", "");
  }
  x[slideIndex-1].style.display = "block";
  dots[slideIndex-1].className += " w3-white";
}
</script>

</body>
</html>
